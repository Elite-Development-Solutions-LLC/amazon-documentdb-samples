[endpoints]
# DocumentDB environment variables
docdb_uri = [DocumentDB cluster URI]
docdb_secret_name = [secrets name for cluster credentials store in AWS Secrets Manager]
# db and collection that will store resume tokens for all collections
statecol = [Name of the collection that will store resume tokens]
statedb = [Name of the database that will store resume tokens]
# ----------------------------------- Uncomment targets to use -----------------------------------------#
# Elastic Search target environment variables
#elasticsearch_uri = [ElasticSearch URI] 
# S3 target environment variables
#bucket = [bucket name]
#path= [path]
# Kafka target environment variables
#kafka_boostrap = [Kafka Bootstrap servers] 
# Kinesis stream environment variables
#kinesis_stream = [Kinesis Stream name]
# SQS environment variables
#sqs_query_url = [SQS Query URL]
# SNS environment variables 
#sns_topic = [ARN of the SNS topic]

# list of dbs and collections in the cluster to replicate events
[collections]
endpoints_dbs_col = [
    {"db":"db1", "cols": ['col11', 'col12', 'col13']},
    {"db":"db2", "cols": ['col21', 'col22', 'col23']}
    ]

# these variables define the network setup for the lambdas that will replicate the events
[network]
vpc_id = [VPC id]
securityGroups = ["sg-1","sg2"]
subnets = [{"subnet":"subnet-1","az":"az-1"},{"subnet":"subnet-2","az":"az-2"},{"subnet":"subnet-3","az":"az-3"}]

# control variables for the solution
[control]
sns_alert = [ARN for the topic to send exceptions]
maxloop = 60
sync = 15
roleArn = [ARN for the role used by the lambda functions]
bucket = [bucket name that hosts the replication code]
key = repLambdaFunction.zip
lambdaTimeout= 120
lambdaMemory= 256
sns_trigger= [ARN for the topic that triggers the lambda functions]